---
title: "The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes"
collection: publications
excerpt: 'Vision-based semantic segmentation in urban scenarios is
a key functionality for autonomous driving. Recent revolutionary results of deep convolutional neural networks (DCNNs) foreshadow the advent of reliable classifiers to perform such visual tasks. However, DCNNs require learning
of many parameters from raw images; thus, having a sufficient amount of diverse images with class annotations is
needed. These annotations are obtained via cumbersome,
human labour which is particularly challenging for semantic segmentation since pixel-level annotations are required.
In this paper, we propose to use a virtual world to automatically generate realistic synthetic images with pixel-level
annotations. Then, we address the question of how useful
such data can be for semantic segmentation â€“ in particular, when using a DCNN paradigm. In order to answer this
question we have generated a synthetic collection of diverse
urban images, named SYNTHIA, with automatically generated class annotations. We use SYNTHIA in combination
with publicly available real-world urban images with manually provided annotations. Then, we conduct experiments
with DCNNs that show how the inclusion of SYNTHIA in the
training stage significantly improves performance on the semantic segmentation task.'
date: 2016-06-27
venue: 'Computer Vision and Pattern Recognition'
paperurl: '(https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf)'
citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
[Download paper here](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf)

