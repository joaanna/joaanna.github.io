---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am pursuing doctoral studies at the Electrical Engineering and Computer Science (EECS) Department at MIT, under the supervision of Prof. Antonio Torralba. My research interests are primarily focused on interpretability and generative AI. Check out my [publications](https://joaanna.github.io/publications/)!

Before embarking on my PhD journey, I completed undergraduate studies in Mathematics at the University of Vienna and The Autonomous University of Barcelona. Following this, I gained industry exposure as an AI Engineer at Twenty Billion Neurons, which was subsequently acquired by Qualcomm. Furthering my academic pursuits, I completed a Master of Science (MSc) degree in Computer Science from the University of Oxford and had the opportunity to contribute as a research intern at the Torr Vision Group.

In addition to my academic and professional commitments, I am actively engaged in the academic community. I serve as a reviewer for several esteemed conferences and journals, including ICCV (2021, 2023), CVPR (2022–2025), ICLR (2022), NeurIPS (2021), ACM FAccT (2024), TPAMI, and IJCV. Furthermore, I co-organize workshops at major conferences, such as [CVG at ICML 2024](https://sites.google.com/view/cvgicml2024) and MIV at CVPR 2025. I have also been co-orgnizing the [MIT Vision and Graphic Seminar](https://sites.google.com/view/visionseminar) since 2022.

------------------
# News

## 2024
- **October** Our work "NewMove: Customizing text-to-video models with novel motions" was accepted at ACCV 2024!
- Our work "Concept sliders: Lora adaptors for precise control in diffusion models" was presented at ECCV 2024!
- We presented our paper "AirLetters: An Open Video Dataset of Characters Drawn in the Air" at HANDS Workshop in ECCV 2024!
- The [work](https://www.dataprovenance.org/consent-in-crisis-paper) in collaboration with the Data Provenance Initiative got accepted at Neurips 2024! 
- **April** Our workshop [Text, Camera, Action!
Frontiers in Controllable Video Generation](https://sites.google.com/view/cvgicml2024) got accepted at the ICML 2024' Conference in Vienna!
- **February** Honoured to be invited as a speaker at the [Rising Stars in AI Symposium 2024
](https://cemse.kaust.edu.sa/ai/aii-symp-2024) in Saudi Arabia!

## 2023
- **December** Our work ["FIND: A Function Description Benchmark for Evaluating Interpretability Methods"](https://multimodal-interpretability.csail.mit.edu/FIND-benchmark/) was accepted at NeurIPS 2023!
- **December** Our work ["Unified Concept Editing in Diffusion Models"](https://unified.baulab.info/) was accepted at WACV 2023!
- **June - August** I had the pleasure to intern at Adobe Research under the supervision of Bryan Russell, Richard Zhang, Josef Sivic and Eli Shechtman.
- **May**: Our paper "Erasing Concepts from Diffusion Models" has been chosen for a spotlight presentation at the [Machine Learning Advances Symposium](https://mlas.mit.edu/).

## 2022
- **July**: Proud to have won the second place of the poster competition at the [International Computer Vision Summer School](https://iplab.dmi.unict.it/icvss2022/CallForPosters) .
- **June**: Our paper "Disentangling visual and written concepts in CLIP" got awarded an Oral  (~4% acceptance rate) at CVPR 22' in New Orleans.
- **June-August** I was fortunate to intern at Netflix Research under the supervision of Mahdi M Kalayeh

------------------


<div><h1>Publications</h1></div>
<div id="publications">
<article class="pub">
  <a classa="pub_image">
    <img src="images/motion.png" alt="" style="background-color: transparent;">
  </a>
  <div class="pub_text">
    <h3 class="papertitle">NewMove: Customizing text-to-video models with novel motions</h3>
    <h4 class="authors" style="font-weight: normal;">
        <b>Joanna Materzyńska</b>, Josef Sivic, Eli Shechtman, Antonio Torralba, Richard Zhang, Bryan Russell
    </h4>
        <p class="conference">ACCV 2024</p>
        [<a href="https://joaanna.github.io/customizing_motion/" target="_blank">website</a>]
        [<a href="https://github.com/adobe-research/custom_motion" target="_blank">code</a>]
  </div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/dpi.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Consent in Crisis: The Rapid Decline of the AI Data Commons</h3>
    <h4 class="authors" style="font-weight: normal;">
       Shayne Longpre, Robert Mahari, Ariel Lee, Campbell Lund, Hamidah Oderinwale, William Brannon, Nayan Saxena, Naana Obeng-Marnu, Tobin South, Cole Hunter, Kevin Klyman, Christopher Klamm, Hailey Schoelkopf, Nikhil Singh, Manuel Cherep, Ahmad Anis, An Dinh, Caroline Chitongo, Da Yin, Damien Sileo, Deividas Mataciunas, Diganta Misra, Emad Alghamdi, Enrico Shippole, Jianguo Zhang, <b>Joanna Materzyńska</b>, Kun Qian, Kush Tiwary, Lester Miranda, Manan Dey, Minnie Liang, Mohammed Hamdy, Niklas Muennighoff, Seonghyeon Ye, Seungone Kim, Shrestha Mohanty, Vipul Gupta, Vivek Sharma, Vu Minh Chien, Xuhui Zhou, Yizhi Li, Caiming Xiong, Luis Villa, Stella Biderman, Hanlin Li, Daphne Ippolito, Sara Hooker, Jad Kabbara, Sandy Pentland
    </h4>
    <p class="conference">NeurIPS 2024 Track on Datasets and Benchmarks</p>
        [<a href="https://arxiv.org/pdf/2407.14933">paper</a>]
  </div>
</article>


<article class="pub">
  <a class="pub_image"><img src="images/airletters.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">AirLetters: An Open Video Dataset of Characters Drawn in the Air</h3>
    <h4 class="authors" style="font-weight: normal;">
        Rishit Dagli, Guillaume Berger, <b>Joanna Materzyńska</b>, Ingo Bax, Roland Memisevic
    </h4>
    <p class="conference">ECCVW 2024 HANDS Workshop </p>
        [<a href="https://arxiv.org/pdf/2410.02921">paper</a>]
  </div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/sliders.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Concept sliders: Lora adaptors for precise control in diffusion models</h3>
    <h4 class="authors" style="font-weight: normal;">
        Rohit Gandikota, <b>Joanna Materzyńska</b>, David Bau, Antonio Torralba
    </h4>
    <p class="conference">ECCV 2024 </p>
        [<a href="https://arxiv.org/pdf/2311.12092">paper</a>]
        [<a href="https://github.com/rohitgandikota/sliders">code</a>]
  </div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/uce.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Unified concept editing in diffusion models</h3>
    <h4 class="authors" style="font-weight: normal;">
      Rohit Gandikota, Hadas Orgad, Yonatan Belinkov, <b>Joanna Materzyńska</b>, David Bau
    </h4>
    <p class="conference">WACV 2024 </p>
    [<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Gandikota_Unified_Concept_Editing_in_Diffusion_Models_WACV_2024_paper.pdf">paper</a>]
    [<a href="https://github.com/rohitgandikota/unified-concept-editing">code</a>]
  </div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/find.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Find: A function description benchmark for evaluating interpretability methods</h3>
    <h4 class="authors" style="font-weight: normal;">
        Sarah Schwettmann, Tamar Shaham, <b>Joanna Materzyńska</b>, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, Antonio Torralba
    </h4>
    <p class="conference">NeurIPS 2023 Track on Datasets and Benchmarks </p>
        [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ef0164c1112f56246224af540857348f-Paper-Datasets_and_Benchmarks.pdf">paper</a>]
        [<a href="https://github.com/multimodal-interpretability/FIND">code</a>]
  </div>
</article>


<article class="pub">
  <a class="pub_image"><img src="images/erasing.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Erasing Concepts from Diffusion Models</h3>
    <h4 class="authors" style="font-weight: normal;">
      <b>Joanna Materzyńska</b>, Rohit Gandikota*, Jaden Fiotto-Kaufman, David Bau
    </h4>
    <p class="conference">ICCV 2023 </p>
      [<a href="https://arxiv.org/pdf/2303.07345">paper</a>]
      [<a href="https://github.com/rohitgandikota/erasing">code</a>]
  </div>
</article>


<article class="pub">
  <a class="pub_image"><img src="images/teaser.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Disentangling visual and written concepts in CLIP</h3>
    <h4 class="authors" style="font-weight: normal;">
      <b>Joanna Materzyńska</b>, Antonio Torralba, David Bau
    </h4>
    <p class="conference">CVPR 2022 <b>(Oral)</b></p>
      [<a href="https://arxiv.org/abs/2206.07835">paper</a>]
      [<a href="https://github.com/joaanna/disentangling_spelling_in_clip">code</a>]
  </div>
</article>




<article class="pub">
  <a class="pub_image"><img src="images/reenacting.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Re-enacting video shots with fictional characters</h3>
    <h4 class="authors" style="font-weight: normal;">
      <b>Joanna Materzynska</b>, David Bau, Antonio Torralba
    </h4>
    <p class="conference">ICCVW 2021 CVEU Workshop (Spotlight) </p>
      [<a href="https://cveu.github.io/src/re_enacting.pdf">paper</a>]
  </div>
</article>


<article class="pub">
  <a class="pub_image"><img src="images/smthelse.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">Something-else: Compositional action recognition with spatial-temporal interaction networks</h3>
    <h4 class="authors" style="font-weight: normal;">
      <b>Joanna Materzyńska</b> Tete Xiao, Roei Herzig, Huijuan Xu, Xiaolong Wang, Trevor Darrell
    </h4>
    <p class="conference">CVPR 2020</p>
      [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Materzynska_Something-Else_Compositional_Action_Recognition_With_Spatial-Temporal_Interaction_Networks_CVPR_2020_paper.pdf">paper</a>]
      [<a href="https://github.com/joaanna/something_else">code</a>]
      [<a href="https://joaanna.github.io/something_else/">website</a>]
  </div>
</article>



<article class="pub">
  <a class="pub_image"><img src="images/jester.jpeg" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">The jester dataset: A large-scale video dataset of human gestures</h3>
    <h4 class="authors" style="font-weight: normal;">
      <b>Joanna Materzyńska</b> Guillaume Berger, Ingo Bax, Roland Memisevic
    </h4>
    <p class="conference">ICCVW 2019 HANDS Workshop</p>
      [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf](https://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Materzynska_The_Jester_Dataset_A_Large-Scale_Video_Dataset_of_Human_Gestures_ICCVW_2019_paper.pdf">paper</a>]
      [<a href="https://www.qualcomm.com/developer/software/jester-dataset">dataset</a>]
</div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/smthsmth.png" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">The "something something" video database for learning and evaluating visual common sense</h3>
    <h4 class="authors" style="font-weight: normal;">
        Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, <b>Joanna Materzyńska</b>, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos, Moritz Mueller-Freitag, Florian Hoppe, Christian Thurau, Ingo Bax, Roland Memisevic
    </h4>
    <p class="conference">ICCV 2017</p>
      [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf">paper</a>]
      [<a href="https://www.qualcomm.com/developer/software/something-something-v-2-dataset">dataset</a>]
  </div>
</article>

<article class="pub">
  <a class="pub_image"><img src="images/synthia.jpg" style="background-color: transparent;"></a>
  <div class="pub_text">
    <h3 class="papertitle">The SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes</h3>
    <h4 class="authors" style="font-weight: normal;">
      German Ros, Laura Sellart, <b>Joanna Materzyńska</b>, David Vazquez, Antonio M Lopez
    </h4>
    <p class="conference">CVPR 2016</p>
      [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf">paper</a>]
  </div>
</article>

</div>



------------------
### To learn more about Captioning & Accessibility resources at the MIT please refer to the [website](https://accessibility.mit.edu/).
